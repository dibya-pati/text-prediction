{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "characterPrediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dibya-pati/seqPrediction/blob/master/characterPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tbHKuVqxJuPk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we will develop a simple LSTM network to learn sequences of characters from Alice in Wonderland. In the next section we will use this model to generate new sequences of characters.\n",
        "\n",
        "Let’s start off by importing the classes and functions we intend to use to train our model."
      ]
    },
    {
      "metadata": {
        "id": "KeqN1p7OJtcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PiuJD8oeK1Us",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we need to load the ASCII text for the book into memory and convert all of the characters to lowercase to reduce the vocabulary that the network must learn."
      ]
    },
    {
      "metadata": {
        "id": "dXUa39y6K2UX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bqWTh9X4NAV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that the book is loaded, we must prepare the data for modeling by the neural network. We cannot model the characters directly, instead we must convert the characters to integers.\n",
        "\n",
        "We can do this easily by first creating a set of all of the distinct characters in the book, then creating a map of each character to a unique integer."
      ]
    },
    {
      "metadata": {
        "id": "amPMvYIbNBzU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IcDg390ZNNLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "7b92b2a1-95d3-43e1-df94-04477abbfd5a"
      },
      "cell_type": "code",
      "source": [
        "char_to_int"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '(': 3,\n",
              " ')': 4,\n",
              " '*': 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '0': 9,\n",
              " '3': 10,\n",
              " ':': 11,\n",
              " ';': 12,\n",
              " '?': 13,\n",
              " '[': 14,\n",
              " ']': 15,\n",
              " '_': 16,\n",
              " 'a': 17,\n",
              " 'b': 18,\n",
              " 'c': 19,\n",
              " 'd': 20,\n",
              " 'e': 21,\n",
              " 'f': 22,\n",
              " 'g': 23,\n",
              " 'h': 24,\n",
              " 'i': 25,\n",
              " 'j': 26,\n",
              " 'k': 27,\n",
              " 'l': 28,\n",
              " 'm': 29,\n",
              " 'n': 30,\n",
              " 'o': 31,\n",
              " 'p': 32,\n",
              " 'q': 33,\n",
              " 'r': 34,\n",
              " 's': 35,\n",
              " 't': 36,\n",
              " 'u': 37,\n",
              " 'v': 38,\n",
              " 'w': 39,\n",
              " 'x': 40,\n",
              " 'y': 41,\n",
              " 'z': 42,\n",
              " '‘': 43,\n",
              " '’': 44,\n",
              " '“': 45,\n",
              " '”': 46}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "PysLUUz3Ng6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see that there may be some characters that we could remove to further clean up the dataset that will reduce the vocabulary and may improve the modeling process.\n",
        "\n",
        "Now that the book has been loaded and the mapping prepared, we can summarize the dataset."
      ]
    },
    {
      "metadata": {
        "id": "ZYfPOZFwNj05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "72ab4fff-531e-43d9-db0a-c6020831f6b5"
      },
      "cell_type": "code",
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  144422\n",
            "Total Vocab:  47\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}